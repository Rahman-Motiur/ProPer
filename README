# ğŸ§  ProPer: Prompt-aware Adaptive Personalization for Multi-rater Medical Image Segmentation

![ProPer Architecture](assets/proper_architecture.png)

**Authors**: Md Motiur Rahman, Saeka Rahman, Smriti Bhatt, Miad Faezipour  
**Published in**: IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2025  
**Paper**: [Link to paper (TBD)](https://arxiv.org/abs/XXXX.XXXXX)  
**Code**: Coming soon on [GitHub](https://github.com/)

---

## ğŸ“Œ Overview

**ProPer** is a novel **single-stage, end-to-end deep learning model** for medical image segmentation that handles multi-rater annotation ambiguity using:

- âœ… Reference-Guided Diversification
- âœ… Prompt-Bank for Rater Expertise
- âœ… Prompt-Aware Attention Mapping (PAAM)
- âœ… Efficient Segmentation with Shared Heads

Unlike existing approaches that struggle with either inefficiency (two-stage) or lack of personalization (one-stage), ProPer effectively combines both diversification and personalization to deliver **state-of-the-art results**.

---

## ğŸ”§ Key Features

- **Dual Encoder-Decoder** setup to learn expert annotation variance.
- **Dynamic Prompt-Bank** to store and update rater-specific styles.
- **PAAM Module** for aligning prompts with feature space.
- **Shared Segmentation Head** for scalable personalization.
- **KL Loss Regularization** for effective supervision without collapse.

---

## ğŸ§ª Datasets Used

| Dataset     | Modality | Annotations | Tasks              |
|-------------|----------|-------------|--------------------|
| LIDC-IDRI   | CT       | 4 Raters    | Lung Nodule Segmentation |
| RIGA        | Fundus   | 6 Raters    | Optic Cup & Disc Segmentation |
| QUBIQ       | MRI/CT   | 3â€“7 Raters  | Brain, Kidney, Prostate Segmentation |

---

## ğŸ“ˆ Performance Highlights

| Dataset     | Metric           | ProPer (Ours) | Previous Best (D-Persona) |
|-------------|------------------|---------------|----------------------------|
| **LIDC-IDRI** | Dice (%)         | **91.90**      | 89.17                     |
|             | GED (â†“)          | **0.1289**     | 0.1444                    |
|             | Dicesoft (â†‘)     | **92.65**      | 90.31                     |
| **RIGA**     | Dice (Disc, Cup) | **97.68, 86.86** | 95.89, 84.40            |
|             | ASSD (â†“)         | **0.77, 4.02** | 1.14, 4.14                |

---

## ğŸ” Research Questions Answered

- **RQ1**: Can end-to-end modeling improve personalization? â†’ âœ… Yes  
- **RQ2**: Does the reference encoder-decoder help? â†’ âœ… Yes  
- **RQ3**: Do PAAM & prompt-bank updates help? â†’ âœ… Yes  
- **RQ4**: Can ProPer outperform crowdsourcing methods? â†’ âœ… Yes

---

## ğŸ“Š Ablation & Generalization

- Ablation confirms each module (KL loss, PAAM, Î»-weighting) improves performance.
- Generalizes well across **new raters** and **unseen modalities** (QUBIQ).
- Robust against **annotation noise** (simulated poisoned raters).

---

## ğŸ’» Implementation Details

- **Framework**: PyTorch  
- **Backbone**: ResNet18 encoder-decoder  
- **Input Sizes**:
  - LIDC-IDRI: 128Ã—128
  - RIGA: 224Ã—224  
- **Training**:
  - Optimizer: Adam
  - LR: 1e-4
  - Scheduler: ReduceLROnPlateau
  - Early stopping with patience = 20

---

## ğŸ“‚ Project Structure (when code is released)

